{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C://Users//Khalis Abd Karim//Desktop//Kidney.csv' , sep = ',' , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.62193430e+01 5.68913399e+03 4.41163970e+01 ... 1.96626590e-02\n",
      "  6.82544876e+00 1.08084090e-02]\n",
      " [4.78248488e+01 4.17099339e+03 3.72733056e+01 ... 3.46985510e-02\n",
      "  6.48294532e+00 1.91937810e-02]\n",
      " [9.01747630e+01 4.55398048e+04 5.67557115e+01 ... 2.41918250e-02\n",
      "  6.21273244e+00 1.30451030e-02]\n",
      " ...\n",
      " [1.70793806e+02 3.75119930e+03 3.06244244e+02 ... 1.26996668e-01\n",
      "  5.74632797e+00 5.73061670e-02]\n",
      " [7.24576467e+01 9.70230777e+04 6.27307322e+01 ... 1.38813520e-02\n",
      "  6.74081918e+00 7.59860000e-03]\n",
      " [2.33571540e+01 3.01539103e+03 2.14060007e+01 ... 7.84395040e-02\n",
      "  5.43780712e+00 5.21666920e-02]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[ : , 1:88].values\n",
    "y = df.iloc[ : , 88].values\n",
    "print (X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "print(scaler.fit(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.98283288e+01  9.91071985e+04  5.03317778e+01  6.92301888e-01\n",
      "  3.14832938e+01  8.28643943e-01  3.30175831e-01  5.25488416e+01\n",
      "  6.57853872e-01  1.05154103e+04  3.86887731e+01  5.51087365e+01\n",
      "  5.14368178e+01  6.83274874e+01 -3.67699243e-01  2.16941484e-01\n",
      "  7.92330476e+01  5.41889803e+08  2.91752672e+01  4.34122742e+01\n",
      "  6.71272144e+08  2.76443319e+02  9.71507713e+01  1.39859571e+02\n",
      " -1.59568341e+02  3.03683844e+00  4.36007244e+02  3.53745205e+03\n",
      "  1.68343746e+00  5.32600104e+00  7.56822434e+01  8.15188507e+01\n",
      "  2.17768299e+01  5.39154943e+00 -6.47977125e+01  1.04470306e-01\n",
      "  1.49069366e+00  1.45211905e+00  3.36027508e+00  2.00863340e+00\n",
      "  1.45792179e+00  2.37479353e+06  1.51282215e+00  1.28505583e+00\n",
      "  1.00484191e+06  1.43563189e+02  4.96586414e+00  2.58263641e+00\n",
      "  4.01236144e+00  2.53001369e+03  5.09630446e+00  9.21880525e+01\n",
      "  7.77718699e-01  5.89109711e-01  1.97957357e+01  1.37301410e-02\n",
      "  6.89157369e+00  1.65558146e-02  1.43752244e-01  6.25184684e-01\n",
      "  9.71419400e+03  2.52574940e+00  1.13895424e+02  3.83496384e+04\n",
      "  8.10227425e-01  3.56458552e+02  7.51134727e-01  4.01441429e-02\n",
      "  4.18998895e+00  1.41236677e+02  6.22347437e-01  1.33854359e+01\n",
      "  3.45365737e+05  9.97429312e-02  2.78700032e-01  1.06322818e+03\n",
      "  4.12269187e+02  3.45859747e+05  6.92326059e+01  6.84695432e-02\n",
      "  3.65843680e+03  4.07876988e+07  1.28241245e+02  5.39116967e-01\n",
      "  2.88856939e-02  6.04577774e+00  1.61792897e-02]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97864193 -0.36866548 -0.14996718 ... -0.44546773  1.48914658\n",
      "  -0.4995076 ]\n",
      " [-0.32280246 -0.37465667 -0.31508    ...  0.28075794  0.83497602\n",
      "   0.28035651]\n",
      " [ 0.81608863 -0.21139861  0.15499922 ... -0.2267114   0.31887811\n",
      "  -0.29148852]\n",
      " ...\n",
      " [ 2.98412867 -0.37631335  6.1747576  ...  4.7387084  -0.57193944\n",
      "   3.82491983]\n",
      " [ 0.33963274 -0.00822478  0.2991669  ... -0.72470182  1.32750681\n",
      "  -0.79802922]\n",
      " [-0.98079764 -0.37921715 -0.69793263 ...  2.39342294 -1.16120435\n",
      "   3.34693363]]\n"
     ]
    }
   ],
   "source": [
    "Xbaru = print(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbaru_train, Xbaru_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 69\n",
      "Before OverSampling, counts of label '0': 13 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (138, 87)\n",
      "After OverSampling, the shape of train_y: (138,) \n",
      "\n",
      "After OverSampling, counts of label '1': 69\n",
      "After OverSampling, counts of label '0': 69\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_sample(Xbaru_train, y_train.ravel()) \n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.001, 'penalty': 'l2'}\n",
      "accuracy : 0.7833333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Grid Search for Logistic Regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(Xbaru_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9a5aeac23e9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbaru_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXbaru_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0maverage_precision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "logreg2=LogisticRegression(C=10,penalty=\"l2\")\n",
    "logreg2.fit(Xbaru_train,y_train)\n",
    "print(logreg2.score(Xbaru_test, y_test))\n",
    "y_pred = logreg2.predict(Xbaru_test)\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "print('precision_score: {0:0.2f}'.format(precision_score))\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "print('recall_score: {0:0.2f}'.format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=42,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 5, 6, 7, 8],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search for Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(Xbaru_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n",
      "0.5952380952380952\n",
      "Average precision-recall score: 0.53\n",
      "precision_score: 0.67\n",
      "recall_score: 0.33\n"
     ]
    }
   ],
   "source": [
    "rfc1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=4, criterion='entropy')\n",
    "rfc1.fit(Xbaru_train, y_train)\n",
    "print(rfc1.score(Xbaru_test, y_test))\n",
    "y_pred=rfc1.predict(Xbaru_test)\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "print('precision_score: {0:0.2f}'.format(precision_score))\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "print('recall_score: {0:0.2f}'.format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search for Gradient Boosting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,50,250,500],\n",
    "    \"max_depth\":[1,3,5,7,9],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n",
       "                                                  criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='deprecated',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 1, 10, 100],\n",
       "                         'max_depth': [1, 3, 5, 7, 9],\n",
       "                         'n_estimators': [5, 50, 250, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = GridSearchCV(gbc,parameters,cv=5)\n",
    "cv.fit(Xbaru_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923076923076923\n",
      "0.6706349206349206\n",
      "Average precision-recall score: 0.62\n",
      "precision_score: 0.88\n",
      "recall_score: 0.39\n"
     ]
    }
   ],
   "source": [
    "cv.fit(Xbaru_train, y_train)\n",
    "print(cv.score(Xbaru_test, y_test))\n",
    "y_pred=cv.predict(Xbaru_test)\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "print('precision_score: {0:0.2f}'.format(precision_score))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "print('recall_score: {0:0.2f}'.format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.722, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.737, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.778, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.722, total=   0.0s\n",
      "{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
      "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Grid Search for Support Vector Machine (SVC)\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(Xbaru_train, y_train) \n",
    "print(grid.best_params_) \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5384615384615384\n",
      "0.5\n",
      "Average precision-recall score: 0.62\n",
      "precision_score: 0.00\n",
      "recall_score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalis Abd Karim\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_curve \n",
    "print(grid.score(Xbaru_test, y_test))\n",
    "y_pred = grid.predict(Xbaru_test) \n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "print('precision_score: {0:0.2f}'.format(precision_score))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "print('recall_score: {0:0.2f}'.format(recall_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'distance'}\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=19, p=2,\n",
      "                     weights='distance')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "#Grid Search for KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "grid_params = {\n",
    "     'n_neighbors': [3,5,11,19],\n",
    "     'weights': ['uniform','distance'],\n",
    "     'metric':['euclidean','manhattan']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "     KNeighborsClassifier(),\n",
    "     grid_params,\n",
    "     verbose = 1,\n",
    "     cv = 3,\n",
    "     n_jobs = -1\n",
    ")\n",
    "gs_results = gs.fit(Xbaru_train, y_train)\n",
    "print(gs_results.best_params_) \n",
    "print(gs_results.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6547619047619049\n",
      "Average precision-recall score: 0.62\n",
      "precision_score: 0.69\n",
      "recall_score: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "print(gs_results.score(Xbaru_test, y_test))\n",
    "y_pred = gs_results.predict(Xbaru_test) \n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "print('precision_score: {0:0.2f}'.format(precision_score))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "print('recall_score: {0:0.2f}'.format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_leaf_nodes': 8, 'min_samples_split': 2}\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=8,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=42, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 882 out of 882 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Grid Search for Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), \n",
    "          'min_samples_split': [2, 3, 4]\n",
    "         }\n",
    "grid_search_cv = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42), \n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3\n",
    ")\n",
    "\n",
    "grid_search_cv = grid_search_cv.fit(Xbaru_train, y_train)\n",
    "print(grid_search_cv.best_params_) \n",
    "print(grid_search_cv.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6507936507936508\n",
      "Average precision-recall score: 0.62\n",
      "precision_score: 0.73\n",
      "recall_score: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "print(grid_search_cv.score(Xbaru_test, y_test))\n",
    "y_pred = grid_search_cv.predict(Xbaru_test) \n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "print('precision_score: {0:0.2f}'.format(precision_score))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "print('recall_score: {0:0.2f}'.format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search for Extra Tree Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(Xbaru_train, y_train)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6410256410256411\n",
      "0.6190476190476191\n",
      "Average precision-recall score: 0.56\n",
      "precision_score: 0.75\n",
      "recall_score: 0.33\n"
     ]
    }
   ],
   "source": [
    "CV_rfc.best_params_\n",
    "rfc1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 200, max_depth=4, criterion='gini')\n",
    "rfc1.fit(Xbaru_train, y_train)\n",
    "print(rfc1.score(Xbaru_test, y_test))\n",
    "y_pred=rfc1.predict(Xbaru_test)\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_pred)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "print('precision_score: {0:0.2f}'.format(precision_score))\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "print('recall_score: {0:0.2f}'.format(recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
